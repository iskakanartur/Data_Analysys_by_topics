{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4995a1",
   "metadata": {},
   "source": [
    "## How to Perform Feature Selection With Numerical Input Data\n",
    "- credits https://machinelearningmastery.com/feature-selection-with-numerical-input-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d559c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1fbcb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 16.527385\n",
      "Feature 1: 131.325562\n",
      "Feature 2: 0.042371\n",
      "Feature 3: 1.415216\n",
      "Feature 4: 12.778966\n",
      "Feature 5: 49.209523\n",
      "Feature 6: 13.377142\n",
      "Feature 7: 25.126440\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOaElEQVR4nO3db4xldX3H8ffHXQWBEiA7kC1LOphsaJG0xUyolsSQrlYshOVBSZYUsrE02yZosW1iF/uA9AEJSRtjH1STDaDbSCFb1LBRa92sGusDwFmg5c+CUEQYWdmxxvqnCRT99sEcyGWcZWfumdlz+e37lWzuPeeeO+ebzeY9Z8+999xUFZKktrxp6AEkSavPuEtSg4y7JDXIuEtSg4y7JDVo/dADAGzYsKGmp6eHHkOS3lAOHDjwg6qaWuqxiYj79PQ0s7OzQ48hSW8oSb57pMc8LSNJDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDZqIT6i2bHrnFwfb9zO3XDbYviUNyyN3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWrQUeOe5PYkh5M8MrLu75I8nuQ/k3w+yWkjj92Y5KkkTyR53xrNLUl6Hcs5cv80cOmidfuAC6rqN4FvAzcCJDkf2Aa8vXvOJ5KsW7VpJUnLctS4V9U3gB8uWveVqnq5W7wX2NTd3wrcVVUvVtV3gKeAi1ZxXknSMqzGOfc/Bv61u3828NzIY3PdOknSMdQr7kn+BngZuOOVVUtsVkd47o4ks0lm5+fn+4whSVpk7Lgn2Q5cDvxRVb0S8DngnJHNNgHPL/X8qtpVVTNVNTM1NTXuGJKkJYwV9ySXAn8NXFFV/zvy0F5gW5ITkpwLbAbu7z+mJGkljvoF2UnuBC4BNiSZA25i4d0xJwD7kgDcW1V/VlWPJtkDPMbC6Zrrq+rnazW8JGlpR417VV29xOrbXmf7m4Gb+wwlSerHT6hKUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOOGvcktyc5nOSRkXVnJNmX5Mnu9vSRx25M8lSSJ5K8b60GlyQd2XKO3D8NXLpo3U5gf1VtBvZ3yyQ5H9gGvL17zieSrFu1aSVJy3LUuFfVN4AfLlq9Fdjd3d8NXDmy/q6qerGqvgM8BVy0OqNKkpZr3HPuZ1XVIYDu9sxu/dnAcyPbzXXrfkmSHUlmk8zOz8+POYYkaSmr/YJqllhXS21YVbuqaqaqZqamplZ5DEk6vo0b9xeSbATobg936+eAc0a22wQ8P/54kqRxjBv3vcD27v524J6R9duSnJDkXGAzcH+/ESVJK7X+aBskuRO4BNiQZA64CbgF2JPkOuBZ4CqAqno0yR7gMeBl4Pqq+vkazS5JOoKjxr2qrj7CQ1uOsP3NwM19hpIk9eMnVCWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhrUK+5J/iLJo0keSXJnkhOTnJFkX5Inu9vTV2tYSdLyjB33JGcDfw7MVNUFwDpgG7AT2F9Vm4H93bIk6Rjqe1pmPfDWJOuBk4Dnga3A7u7x3cCVPfchSVqhseNeVd8D/h54FjgE/E9VfQU4q6oOddscAs5cjUElScvX57TM6SwcpZ8L/CpwcpJrVvD8HUlmk8zOz8+PO4YkaQl9Tsu8B/hOVc1X1f8BnwN+F3ghyUaA7vbwUk+uql1VNVNVM1NTUz3GkCQt1ifuzwLvTHJSkgBbgIPAXmB7t8124J5+I0qSVmr9uE+sqvuS3A08ALwMPAjsAk4B9iS5joVfAFetxqCSpOUbO+4AVXUTcNOi1S+ycBQvSRqIn1CVpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAb1inuS05LcneTxJAeTvCvJGUn2JXmyuz19tYaVJC1P3yP3fwC+XFW/DvwWcBDYCeyvqs3A/m5ZknQMjR33JKcC7wZuA6iql6rqR8BWYHe32W7gyn4jSpJWqs+R+9uAeeBTSR5McmuSk4GzquoQQHd75lJPTrIjyWyS2fn5+R5jSJIW6xP39cA7gE9W1YXAz1jBKZiq2lVVM1U1MzU11WMMSdJifeI+B8xV1X3d8t0sxP6FJBsButvD/UaUJK3U2HGvqu8DzyU5r1u1BXgM2Ats79ZtB+7pNaEkacXW93z+h4A7krwFeBr4AAu/MPYkuQ54Friq5z4kSSvUK+5V9RAws8RDW/r8XElSP35CVZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIa1PfCYZImyPTOLw6272duuWywfeuXeeQuSQ0y7pLUIOMuSQ0y7pLUIOMuSQ0y7pLUIOMuSQ0y7pLUIOMuSQ0y7pLUIOMuSQ3qHfck65I8mOQL3fIZSfYlebK7Pb3/mJKklViNI/cbgIMjyzuB/VW1GdjfLUuSjqFecU+yCbgMuHVk9VZgd3d/N3Bln31Iklau75H7x4GPAL8YWXdWVR0C6G7PXOqJSXYkmU0yOz8/33MMSdKoseOe5HLgcFUdGOf5VbWrqmaqamZqamrcMSRJS+jzZR0XA1ck+QPgRODUJJ8BXkiysaoOJdkIHF6NQSVJyzf2kXtV3VhVm6pqGtgGfLWqrgH2Atu7zbYD9/SeUpK0ImvxPvdbgPcmeRJ4b7csSTqGVuU7VKvq68DXu/v/DWxZjZ8rSRqPn1CVpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAatyjcxSdIb2fTOLw6272duuWxNfq5H7pLUIOMuSQ0y7pLUIOMuSQ0aO+5JzknytSQHkzya5IZu/RlJ9iV5srs9ffXGlSQtR58j95eBv6qq3wDeCVyf5HxgJ7C/qjYD+7tlSdIxNHbcq+pQVT3Q3f8JcBA4G9gK7O422w1c2XNGSdIKrco59yTTwIXAfcBZVXUIFn4BAGce4Tk7kswmmZ2fn1+NMSRJnd5xT3IK8Fngw1X14+U+r6p2VdVMVc1MTU31HUOSNKJX3JO8mYWw31FVn+tWv5BkY/f4RuBwvxElSSvV590yAW4DDlbVx0Ye2gts7+5vB+4ZfzxJ0jj6XFvmYuBa4OEkD3XrPgrcAuxJch3wLHBVrwklSSs2dtyr6ptAjvDwlnF/riSpvyauCtniFd0kqQ8vPyBJDTLuktQg4y5JDTLuktSgJl5QlTT5fOPDsWXcpRUyUnoj8LSMJDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg9Ys7kkuTfJEkqeS7Fyr/UiSftmafBNTknXAPwLvBeaAbyXZW1WPrcX+1B6/7UjqZ62O3C8Cnqqqp6vqJeAuYOsa7UuStEiqavV/aPKHwKVV9Sfd8rXA71TVB0e22QHs6BbPA55Y9UGWZwPwg4H2fTTONh5nG4+zjWfI2X6tqqaWemCtviA7S6x7zW+RqtoF7Fqj/S9bktmqmhl6jqU423icbTzONp5JnW2tTsvMAeeMLG8Cnl+jfUmSFlmruH8L2Jzk3CRvAbYBe9doX5KkRdbktExVvZzkg8C/AeuA26vq0bXY1yoY/NTQ63C28TjbeJxtPBM525q8oCpJGpafUJWkBhl3SWrQcR33Sb1EQpLbkxxO8sjQsyyW5JwkX0tyMMmjSW4YeqZXJDkxyf1J/qOb7W+HnmlUknVJHkzyhaFnWSzJM0keTvJQktmh5xmV5LQkdyd5vPt3966hZwJIcl739/XKnx8n+fDQc73iuD3n3l0i4duMXCIBuHoSLpGQ5N3AT4F/qqoLhp5nVJKNwMaqeiDJrwAHgCsn5O8twMlV9dMkbwa+CdxQVfcOPBoASf4SmAFOrarLh55nVJJngJmqmrgPCiXZDfx7Vd3avfvupKr60cBjvUbXk++x8GHN7w49DxzfR+4Te4mEqvoG8MOh51hKVR2qqge6+z8BDgJnDzvVglrw027xzd2fiTh6SbIJuAy4dehZ3kiSnAq8G7gNoKpemrSwd7YA/zUpYYfjO+5nA8+NLM8xIZF6o0gyDVwI3DfwKK/qTn08BBwG9lXVpMz2ceAjwC8GnuNICvhKkgPdpUEmxduAeeBT3SmtW5OcPPRQS9gG3Dn0EKOO57gf9RIJOrIkpwCfBT5cVT8eep5XVNXPq+q3WfhU9EVJBj+tleRy4HBVHRh6ltdxcVW9A3g/cH13anASrAfeAXyyqi4EfgZMzOtjAN2poiuAfxl6llHHc9y9RMKYuvPZnwXuqKrPDT3PUrr/un8duHTYSQC4GLiiO699F/B7ST4z7EivVVXPd7eHgc+zcNpyEswBcyP/A7ubhdhPkvcDD1TVC0MPMup4jruXSBhD96LlbcDBqvrY0POMSjKV5LTu/luB9wCPDzoUUFU3VtWmqppm4d/ZV6vqmoHHelWSk7sXx+lOefw+MBHv1Kqq7wPPJTmvW7UFGPzF+0WuZsJOycDaXRVy4k3yJRKS3AlcAmxIMgfcVFW3DTvVqy4GrgUe7s5tA3y0qr403Eiv2gjs7t658CZgT1VN3NsOJ9BZwOcXfm+zHvjnqvrysCO9xoeAO7qDsKeBDww8z6uSnMTCO+7+dOhZFjtu3wopSS07nk/LSFKzjLskNci4S1KDjLskNci4S1KDjLskNci4S1KD/h8WJa9aL+j97QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename, header=None)\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\treturn X, y\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\t# configure to select all features\n",
    "\tfs = SelectKBest(score_func=f_classif, k='all')\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_train, y_train)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\t# transform test input data\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('data/pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d28f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0011f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b06d655",
   "metadata": {},
   "source": [
    "## Model Built Using ANOVA f-test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05892ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.74\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename, header=None)\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\treturn X, y\n",
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\t# configure to select a subset of features\n",
    "\tfs = SelectKBest(score_func=f_classif, k=4)\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_train, y_train)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\t# transform test input data\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('data/pima-indians-diabetes.csv')\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the example reports the performance of the model on just four of the eight input \n",
    "## features selected using the ANOVA f-test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391733d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a652c21d",
   "metadata": {},
   "source": [
    "## Tune the Number of Selected Features\n",
    "- In the previous example, we selected four features, but how do we know that is a good or best number of features to select?\n",
    "- Instead of guessing, we can systematically test a range of different numbers of selected features and discover which results in the best performing model. This is called a grid search, where the k argument to the SelectKBest class can be tuned.\n",
    "- t is good practice to evaluate model configurations on classification tasks using repeated stratified k-fold cross-validation. We will use three repeats of 10-fold cross-validation via the RepeatedStratifiedKFold class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae53810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Accuracy: 0.770\n",
      "Best Config: {'anova__k': 7}\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename, header=None)\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\treturn X, y\n",
    " \n",
    "# define dataset\n",
    "X, y = load_dataset('data/pima-indians-diabetes.csv')\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the pipeline to evaluate\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "fs = SelectKBest(score_func=f_classif)\n",
    "pipeline = Pipeline(steps=[('anova',fs), ('lr', model)])\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['anova__k'] = [i+1 for i in range(X.shape[1])]\n",
    "# define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print('Best Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3dc859",
   "metadata": {},
   "source": [
    "### \n",
    "- Running the example grid searches different numbers of selected features using ANOVA f-test, where each modeling pipeline is evaluated using repeated cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e916f8",
   "metadata": {},
   "source": [
    "## Number of features and accuracy\n",
    "- We might want to see the relationship between the number of selected features and classification accuracy. In this relationship, we may expect that more features result in a better performance to a point.\n",
    "- This relationship can be explored by manually evaluating each configuration of k for the SelectKBest from 1 to 8, gathering the sample of accuracy scores, and plotting the results using box and whisker plots side-by-side. The spread and mean of these box plots would be expected to show any interesting relationship between the number of selected features and the classification accuracy of the pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c881a2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.748 (0.048)\n",
      ">2 0.756 (0.042)\n",
      ">3 0.761 (0.044)\n",
      ">4 0.759 (0.042)\n",
      ">5 0.770 (0.041)\n",
      ">6 0.766 (0.042)\n",
      ">7 0.770 (0.042)\n",
      ">8 0.768 (0.040)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdata = read_csv(filename, header=None)\n",
    "\t# retrieve numpy array\n",
    "\tdataset = data.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\treturn X, y\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = load_dataset('data/pima-indians-diabetes.csv')\n",
    "# define number of features to evaluate\n",
    "num_features = [i+1 for i in range(X.shape[1])]\n",
    "# enumerate each number of features\n",
    "results = list()\n",
    "for k in num_features:\n",
    "\t# create pipeline\n",
    "\tmodel = LogisticRegression(solver='liblinear')\n",
    "\tfs = SelectKBest(score_func=f_classif, k=k)\n",
    "\tpipeline = Pipeline(steps=[('anova',fs), ('lr', model)])\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(pipeline, X, y)\n",
    "\tresults.append(scores)\n",
    "\t# summarize the results\n",
    "\tprint('>%d %.3f (%.3f)' % (k, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=num_features, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf9b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43cbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830501f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
