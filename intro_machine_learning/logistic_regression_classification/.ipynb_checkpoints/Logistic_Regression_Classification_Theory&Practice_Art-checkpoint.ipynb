{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1837a6ea",
   "metadata": {},
   "source": [
    "# Logistic Regression - for classification\n",
    "- target value is a binary variable instead of a continuous value\n",
    "- The effect of applying the logistic function is to compress the output of the linear function so that it's limited to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08941716",
   "metadata": {},
   "source": [
    "## PART 1 - A quick Intro \n",
    "- credits https://www.youtube.com/watch?v=yIYKR4sgzI8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Review - Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03fc43f",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5558316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression - First glance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a33365",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instead of fitting a line to the data logsistic regression is an S shape function \n",
    "## the curve goes from 0 to 1 and that means that the curve tells you the probability \n",
    "## that a mouse is obese based on its weight "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec0cb3",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l3.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c35b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic regression for classification\n",
    "### see probabilties on picture at different postions. Heavy mouse 80 % prob that is obese\n",
    "### etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f6e42",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l4.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification Obese not obese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed1f1d",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l5.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression as a machine learning model to make preditcions:\n",
    "### continuous and categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82bf849",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l6.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can TEST THE SIGNIFICANCE OF EACH VARIABLE IN PREDICTIONS!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9cb19",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l7.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ad66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HOW IMPORTANT IS THE VARIABLE IN THE MODEL? Test to see if a variable's effect\n",
    "### on the prediction is different from 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82c3a3",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l8.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f96cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Difference Logistic vs Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1364e2",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l9.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9861a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lieanr Regression - Least Squares method to minimize Error (y hat minus y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be0419",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l10.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dfbb5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No R suqared for ligistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750ac40",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l11.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression - MAXIMUM LIKELIHOOD\n",
    "### step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe20c8",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l12.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cdf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression - MAXIMUM LIKELIHOOD\n",
    "### step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5371db75",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l4.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9249cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression - MAXIMUM LIKELIHOOD\n",
    "### step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f3fac",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l13.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48275023",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression - MAXIMUM LIKELIHOOD\n",
    "### step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa47346",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l14.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression - MAXIMUM LIKELIHOOD\n",
    "### step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e00d85",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l15.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7696de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression - MAXIMUM LIKELIHOOD\n",
    "### Then you shift the line and calculate the new likelihood of the data (see pale dotted lines)\n",
    "### Then shift the line anc calculate the likelihood again\n",
    "### (pale dotted lines)\n",
    "### FINALLY THE LINE WITH MAX LIKELIHOOD IS SELECTED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcb40f",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l16.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc18cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bbcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### On Logistic Regression COeffs https://www.youtube.com/watch?v=vN5cNN2-HWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46611a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistci Regression Y axis takes probabilities of from 0 to 1, so to solve that problem\n",
    "### we take the log . So like the y axis of a LINEAR reg, it can go from minus infinity to plus infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439dd55",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l17.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistc Regression y axis transfomtaion from 0 t0 1 to ifinites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee5e87",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l18.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d66b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abf7976b",
   "metadata": {},
   "source": [
    "## PART 2 : Categorical Variables, Problems with linear models, Logistic Model\n",
    "- Negative probabilities in linear models \n",
    "- https://www.youtube.com/watch?v=gNhogKJ_q7U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CONTINUOUS vs Categorical Variables : General Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d5051",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l19.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21deaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLES OF BINARY OUTCOMES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb4cb5d",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l20.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binary Outcomes YES OR NO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec3af3",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l21.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2924d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69978ef",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l22.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COULD WE USE A INEAR REGRESSION IN THE EXAMPLE?\n",
    "## We could and here it is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd6048",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l23.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007accbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## And the Statistics output of Regression model is\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bce1d8",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l24.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790de171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Still with the Linear Regression : INTERPRETING THE RESULTS\n",
    "## EVERY ADDITIONAL YEAR OF AGE INCREASES the PROBABIITY OF\n",
    "## SUBSCRIPTION BY 6.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8bc78e",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l25.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a52aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROBLEMS WITH LINEAR REGRESSION (NEGATIVE PROBABILITIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfb27f",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l26.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Trying to handle negative probabilities by cutting the edges - making them zero \n",
    "### Hint doesn't work well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb265da",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l27.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb26a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fixing the Prior Approach "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878fb77",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l28.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39303b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 Codnitions - Proprtions \n",
    "##  Dividing the same number with a number greater than istelf (+1) gives a smaller ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fd0e6",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l30.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45134aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LINEAR FUNCTION IS NOT GONE\n",
    "## ln for log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3792b52",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l31.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f1600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63125e13",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l33a.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b48d15",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l33.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Logsitic Regression Model\n",
    "## No negative probabilities any more\n",
    "## Rather as the customer gets older the probability of becoming a subcriber\n",
    "## asimptotically gets coser to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69db89",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l34.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91fc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e12b474",
   "metadata": {},
   "source": [
    "## PART 3 CLASSIFICATION : Linear Models for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we show the same type of diagram that we showed for linear regression with the input variables,  \n",
    "## xi in the left boxes and the model coefficients wi and b above the arrows. T\n",
    "## he logistic regression model still computes a weighted sum of the input features xi \n",
    "## and the intercept term b, \n",
    "## but it runs this result through a special non-linear function f, \n",
    "## the logistic function represented by this new box in the middle of the diagram to produce the output y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792bb161",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l35.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOGISTIC REGRESSION A REALISTIC EXAMPLE\n",
    "### Suppose we want to whether or not a student will pass a final exam based on a single input variable \n",
    "## that's the number of hours they spend studying for the exam.\n",
    "\n",
    "## Students who end up failing the exam are assigned to the negative class, which corresponds to a \n",
    "##target value of 0. And students who pass the exam are assigned to the positive class and \n",
    "## associated with a target value of 1.\n",
    "\n",
    "##This plot shows an example training set. The x-axis corresponds to the number of hours studied \n",
    "## and the y-axis corresponds to the probability of passing the exam.\n",
    "##The red points to the left, with a target value of 0 represent points in the training set, \n",
    "##which are examples of students who failed the exam, along with the number of hours they spent studying.\n",
    "\n",
    "## Likewise, the blue points with target value 1 on the right represent points in the training set, \n",
    "## corresponding to students who passed the exam. With their x values representing the number of \n",
    "##hours those students spent studying.\n",
    "\n",
    "## Using logistic regression, we can estimate model coefficients for w hat and b hat that \n",
    "## produce a logistic curve that best fits these training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AND THE CLASSIFICATION !!!\n",
    "## Students who estimated probability of passing the exam is greater than or equal to 50% are\n",
    "## predicted to be in the positive class. Otherwise, they're predicted to be in the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e8cd7",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l39.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b34dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### and then we can go to 3DIMENSIONAL space - with 2 Features\n",
    "\n",
    "### Once this logistic function has been estimated from the training data, we can use it \n",
    "## to predict the class membership for any point, given its Feature 1 and Feature 2 values, \n",
    "##same way we did for the exam example.\n",
    "\n",
    "### Any data instances whose logistic probability estimate y hat is greater than or equal to 0.5 are \n",
    "## predicted to be in the positive blue class,\n",
    "## otherwise, in the other red class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f5bd7",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l40.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE BOUNDYRY  using logistic regression gives a linear decision boundary between the classes as shown here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66a7aed",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l41.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509ad34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a66cfe33",
   "metadata": {},
   "source": [
    "## PART 3 : EVALUATION : Confusion Matrices, ROC Curve and Basic Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebf1c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Represent Train  Evaluate Refine Cycle\n",
    "## Its an Art))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42978f54",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l55.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8c394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ff70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrices & Basic Evaluation Metrics\n",
    "## DIFFERENT ERROR TYPES\n",
    "\n",
    "## The black points here are the instances with true class positive namely the digit one and \n",
    "## the white points have true class negative, that is, there are all the other digits except for one. \n",
    "\n",
    "## The black line shows a hypothetical linear classifier's decision BOUNDRY  for which any instance \n",
    "## to the left of the decision boundary is predicted to be in the positive class and everything to \n",
    "##the right of the decision boundary is predicted to be in the negative class. \n",
    "\n",
    "##The true positive points are those black points in the positive prediction region and \n",
    "## false positives are those white points in the positive prediction region. \n",
    "\n",
    "## Likewise, true negatives are the white points in the negative prediction region and false negatives \n",
    "## are black points in the negative prediction region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36267113",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l42.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACCURACY\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e80aa4",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l43.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efef354",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASSIFICATION ERROR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867a2d4",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l44.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452daac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!! RECALL OR TRUE POSITIVE RATE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53b06f",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l45.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFICITY - FALSE POSITIVE RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4b7f72",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l46.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740bd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRECISION RECALL TRADEOFF\n",
    "\n",
    "\n",
    "## We can see that a PRECISION of 0.68 means that about 68 percent of the points in the \n",
    "## positive prediction region to the left of the decision boundary or 13 out of the 19 instances \n",
    "## are correctly labeled as positive. \n",
    "\n",
    "## A RECALL  of 0.87 means, that of all true positive instances, so all black points in the figure, \n",
    "## the positive prediction region has 'found about 87 percent of them' or 13 out of 15.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4c290",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l47.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9689d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## High precision low Recall: IT HAS A COST !!! SEE BELOW\n",
    "\n",
    "## SOMETIMES WE WANT HIGHER PRECISION SUCH AS SEARCH ENGINE QUERYIES\n",
    "## If we wanted a classifier that was oriented towards higher levels of precision like \n",
    "## in the search engine query suggestion task, we might want a decision boundary instead that look like this.\n",
    "\n",
    "## THE COST\n",
    "## Now, this comes at a cost because out of the 15 total positive instances 8 of them are now FALSE negatives, \n",
    "## in other words, they're INCORRECTLY  PREDICTED as being negative. \n",
    "## And so, recall drops to 7 divided by 15 or 0.47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4985c454",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l48.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab737c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tumor Detection Type of Tasks where the Error is VERY COSTLY\n",
    "\n",
    "## On the other hand, if our classification task is like the tumor detection example, \n",
    "## we want to minimize false negatives and obtain high recall. \n",
    "## In which case, we would want the classifier's decision boundary to look more like this. \n",
    "## Now, all 15 positive instances have been correctly predicted as being in the positive class, \n",
    "## which means these tumors have all been detected. \n",
    "\n",
    "##However, this also comes with a cost since the number of false positives, \n",
    "## things that the detector triggers as possible tumors for example that are actually not, \n",
    "## has gone up. So, recall is a perfect 1.0 score but the precision has dropped to 15 out of 42 or 0.36. \n",
    "\n",
    "## These examples illustrate a classic trade-off that often appears in machine learning applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbc822",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l49.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb85158",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THE TRADEOFF PRECISION - RECALL and APPLICATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844e343",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l50.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72bf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## F SCORE !!! PARAMETER BETA - Adjust Precision vs Recall with Beta\n",
    "\n",
    "## This F1 score is a special case of a more general evaluation metric known as an F score \n",
    "## that introduces a PARAMETER BETA. \n",
    "\n",
    "## By ADJSUTING  BETA we can CONTROL  how much emphasis an evaluation is given to precision versus recall. \n",
    "\n",
    "## For example, if we have PRECISION ORINETED users, we might say a beta equal to 0.5, \n",
    "## since we want false positives to hurt performance more than false negatives. \n",
    "\n",
    "## For RECALL  ORIENTED situations, we might set beta to a number larger than one, say two, \n",
    "## to emphasize that false negatives should hurt performance more than false positives. \n",
    "\n",
    "## The setting of beta equals one corresponds to the F1 score special case that we just saw \n",
    "## that weights precision and recall equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b338d55",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l51.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRECSION RECALL CURVES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a411c",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l52.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC CURVES \n",
    "\n",
    "## ROC curves or receiver operating characteristic curves are a very widely used visualization method \n",
    "## that illustrate the performance of a binary classifier.\n",
    "\n",
    "## ROC curves on the X-axis show a classifier's False Positive Rate so that would go \n",
    "## from 0 to 1.0, and on the Y-axis they show a classifier's True Positive Rate so that will also go \n",
    "## from 0 to 1.0. \n",
    "\n",
    "## The ideal point in ROC space is one where the classifier achieves zero, \n",
    "## a false positive rate of zero, and a true positive rate of one. So that would be the upper left corner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a0a2c",
   "metadata": {},
   "source": [
    "<img src=\"pics_logistic/l54.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4a075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff31edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"pics_logistic/l49.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2da44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"pics_logistic/l49.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a91b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286d1d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e80a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e56f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfaa2e13",
   "metadata": {},
   "source": [
    "## PART 4 : Practical - predict diabetes using the Logistic Regression Classifier.\n",
    "-allcredist go to https://www.datacamp.com/tutorial/understanding-logistic-regression-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0291075c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas\n",
    "import pandas as pd\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "# load dataset\n",
    "pima = pd.read_csv(\"pima-indians-diabetes.csv\", header=None, names=col_names)\n",
    "#pima = pd.read_csv(\"diabetes.csv\", header=None, names=col_names)\n",
    "#pima = pima[1:]\n",
    "pima.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d11ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pregnant</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigree</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pregnant   glucose        bp      skin   insulin       bmi  \\\n",
       "pregnant  1.000000  0.129459  0.141282 -0.081672 -0.073535  0.017683   \n",
       "glucose   0.129459  1.000000  0.152590  0.057328  0.331357  0.221071   \n",
       "bp        0.141282  0.152590  1.000000  0.207371  0.088933  0.281805   \n",
       "skin     -0.081672  0.057328  0.207371  1.000000  0.436783  0.392573   \n",
       "insulin  -0.073535  0.331357  0.088933  0.436783  1.000000  0.197859   \n",
       "bmi       0.017683  0.221071  0.281805  0.392573  0.197859  1.000000   \n",
       "pedigree -0.033523  0.137337  0.041265  0.183928  0.185071  0.140647   \n",
       "age       0.544341  0.263514  0.239528 -0.113970 -0.042163  0.036242   \n",
       "label     0.221898  0.466581  0.065068  0.074752  0.130548  0.292695   \n",
       "\n",
       "          pedigree       age     label  \n",
       "pregnant -0.033523  0.544341  0.221898  \n",
       "glucose   0.137337  0.263514  0.466581  \n",
       "bp        0.041265  0.239528  0.065068  \n",
       "skin      0.183928 -0.113970  0.074752  \n",
       "insulin   0.185071 -0.042163  0.130548  \n",
       "bmi       0.140647  0.036242  0.292695  \n",
       "pedigree  1.000000  0.033561  0.173844  \n",
       "age       0.033561  1.000000  0.238356  \n",
       "label     0.173844  0.238356  1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5254c980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab670a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima[pima.label == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0883222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima[pima.label == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c97644",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting Feature\n",
    "## Here, you need to divide the given columns into two types of variables dependent(or target variable) \n",
    "## and independent variable(or feature variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7969fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split dataset in features and target variable\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "## feature_cols = ['bmi', 'age','glucose','bp'] TEST\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.label # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cba68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting Data\n",
    "## To understand model performance, dividing the dataset into a training set and a test set \n",
    "## is a good strategy. Let's split the dataset by using the function train_test_split(). \n",
    "##You need to pass 3 parameters: features, target, and test_set size. \n",
    "## Additionally, you can use random_state to select records randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b662249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712cee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Development and Prediction\n",
    "## First, import the Logistic Regression module and create a Logistic Regression classifier object\n",
    "## using the LogisticRegression() function with random_state for reproducibility. \n",
    "##Then, fit your model on the train set using fit() and perform prediction on the test set using predict(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64336c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=16)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f2a5492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5462a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabe0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation using Confusion Matrix\n",
    "## A confusion matrix is a table that is used to evaluate the performance of a classification model. \n",
    "## You can also visualize the performance of an algorithm. The fundamental of a confusion matrix is the number of\n",
    "## correct and incorrect predictions summed up class-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80076044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115,  10],\n",
       "       [ 25,  42]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the metrics class\n",
    "## Here, you can see the confusion matrix in the form of the array object. \n",
    "## The dimension of this matrix is 2*2 because this model is binary classification. \n",
    "## You have two classes 0 and 1. \n",
    "## Diagonal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. \n",
    "## In the output, 115 and 42 are actual predictions, and 25 and 10 are incorrect predictions\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing Confusion Matrix using Heatmap\n",
    "## Let's visualize the results of the model in the form of a confusion matrix using matplotlib and seaborn.\n",
    "## Here, you will visualize the confusion matrix using Heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "697820ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "#Text(0.5,257.44,'Predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3473898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bed00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix Evaluation Metrics\n",
    "## Let's evaluate the model using classification_report for accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7d9a768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "without diabetes       0.82      0.92      0.87       125\n",
      "   with diabetes       0.81      0.63      0.71        67\n",
      "\n",
      "        accuracy                           0.82       192\n",
      "       macro avg       0.81      0.77      0.79       192\n",
      "    weighted avg       0.82      0.82      0.81       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['without diabetes', 'with diabetes']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "## Well, you got a classification rate of 80%, considered as good accuracy. \n",
    "\n",
    "## PRECISION : Precision is about being precise, i.e., how accurate your model is. In other words, \n",
    "## you can say, when a model makes a prediction, how often it is correct. \n",
    "## In your prediction case, when your Logistic Regression model predicted patients are going to \n",
    "## suffer from diabetes, that patients have 73% of the time. \n",
    "\n",
    "## RECALL: If there are patients who have diabetes in the test set and your Logistic Regression model can identify it 57% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC Curve\n",
    "## Receiver Operating Characteristic(ROC) curve is a plot of the true positive rate against \n",
    "## the false positive rate. It shows the tradeoff between sensitivity and specificity.\n",
    "\n",
    "## AUC score for the case is 0.88. AUC score 1 represents a perfect classifier, \n",
    "## and 0.5 represents a worthless classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e5230d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11714adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ff9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb038aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b730f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ee737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b508d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7aea58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
